{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and using data from text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different ways of reading data in from text files. These examples start from the assumption that you have a textfile with a list of data, possibly spanning multiple columns.\n",
    "\n",
    "## `np.loadtxt`\n",
    "This is the simplest method. (And probably the most limited.) It uses a numpy method called loadtxt to read in textfile data, as long as the data is regularly formatted (an MxN grid of data). It also assumes you have no missing values. Some more advanced methods are covered towards the end of this tutorial if you have more complex data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "myData = np.loadtxt(\"test_rainfile_hourly.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.2,   0.6,   0.6, ...,   0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ],\n",
       "       ..., \n",
       "       [  0.1,   1.1,   1. , ...,  12.5,  12.5,   3.6],\n",
       "       [  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the object `myData` is a 2-Dimensional array, filled with the values in the sample text data file. The `loadtxt` method has automatically created us an array with all of our data parsed into it from the text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting subsets of data\n",
    "Now we are going to extract certain subsets of this (or these...) data. We can do this with something called array splicing - a built in feature of numpy arrays. Suppose we want the first column of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.2,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,\n",
       "         0. ,   0. ,   0. ,   0. ,   1.5,  15.8,   0. ,   0.3,   1. ,\n",
       "         0. ,   0. ,   0. ,   0.1,   0. ,   0. ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some explanation. Numpy (and Python in general) stores array data in row-major order. So when you want to access a certain data element within an array, you specifiy the row first, and then the column. Note that Python starts counting array positions from zero!\n",
    "\n",
    "So here we are using the wildcard `:` symbol to say we want all elements from the row dimension, and `0` to say we want the \"zeroth-column\". This gives us a view of the array's first column.\n",
    "\n",
    "If we wanted the first row, we could just specifiy the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.2,  0.6,  0.6,  0.6,  0.6,  0.6,  0.3,  0.3,  0.3,  0.3,  0.3,\n",
       "        0.1,  0.1,  0.1,  0.1,  0.1,  0. ,  4.3,  2. ,  2. ,  2. ,  2. ,\n",
       "        2. ,  2.3,  2.3,  2.3,  2.3,  2.3,  0.1,  0.1,  0.1,  0.1,  0.1,\n",
       "        0. ,  4.3,  2. ,  2. ,  2. ,  2. ,  2. ,  2.3,  2.3,  2.3,  2.3,\n",
       "        2.3,  0.1,  0.1,  0.1,  0.1,  0.1,  0. ,  4.3,  2. ,  2. ,  2. ,\n",
       "        2. ,  2. ,  2.3,  2.3,  2.3,  2.3,  2.3,  0.1,  0.1,  0.1,  0.1,\n",
       "        0.1,  0. ,  4.3,  2. ,  2. ,  2. ,  2. ,  2. ,  2.3,  2.3,  2.3,\n",
       "        2.3,  2.3,  0.1,  0.1,  0.1,  0.1,  0.1,  0. ,  4.3,  2. ,  2. ,\n",
       "        2. ,  2. ,  2. ,  2.3,  2.3,  2.3,  2.3,  2.3,  0.1,  0.1,  0.1,\n",
       "        0.1,  0.1,  0. ,  5.5,  2. ,  2. ,  2. ,  2. ,  2. ,  0.3,  0.3,\n",
       "        0.3,  0.3,  0.3,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  5.5,  2. ,\n",
       "        2. ,  2. ,  2. ,  2. ,  0.3,  0.3,  0.3,  0.3,  0.3,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  5.5,  2. ,  2. ,  2. ,  2. ,  2. ,  0.3,\n",
       "        0.3,  0.3,  0.3,  0.3,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  5.5,\n",
       "        2. ,  2. ,  2. ,  2. ,  2. ,  0.3,  0.3,  0.3,  0.3,  0.3,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  5.5,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "        0.3,  0.3,  0.3,  0.3,  0.3,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        7.5,  0.6,  0.6,  0.6,  0.6,  0.6,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  7.5,  0.6,  0.6,  0.6,  0.6,\n",
       "        0.6,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  7.5,  0.6,  0.6,  0.6,  0.6,  0.6,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  7.5,  0.6,  0.6,  0.6,\n",
       "        0.6,  0.6,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  7.5,  0.6,  0.6,  0.6,  0.6,  0.6,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.6,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0.6,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.6,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0.6,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.6,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0.4,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0.4,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.4,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "        0. ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if we want the second a third columns, we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.6,   0.6],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  1.5,   0.4],\n",
       "       [ 21.1,  21.1],\n",
       "       [  1.7,   1.7],\n",
       "       [  1.1,   1.1],\n",
       "       [  1.3,   1. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  1.1,   1. ],\n",
       "       [  0. ,   0. ],\n",
       "       [  0. ,   0. ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData[:,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax of the array splicing is perhaps slightly confusing at first. You may have thought (or forgot, like I did when writing this) that when you specify a range of elements in an array splice, the range is upto *but not including* the upper range bound. i.e. `myData[:,1:2]` would only give you one column of data.\n",
    "\n",
    "#### Summary\n",
    "The colon syntax (`:`) specifies a range. However, omitting any bounds on the range will return the whole set of data from that dimension.\n",
    "\n",
    "### More splicing\n",
    "You can extract a rectangular subset of data using the same notation: Here we are going to ask for four rows of data, and from those rows, two columns of data. (Don't worry that they are all zeros - that's just part of the dataset and is correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData[2:6,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo and behold, we now have a 4x2 subset of the original `myData` array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A note on creating new arrays\n",
    "By design, creating a new 'view' of an array by slicing **does not** create a copy of that array. It simply creates a view of the original array. If you modify the original array, your view will also change as well. This might be what you intended, but often it is not.\n",
    "\n",
    "If you want a separate array to work on, use the copy function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = myData[2:6,1:3].copy()\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look what happens if you don't use copy, but use a simple assignment operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = myData[2:6,1:3]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myData += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.,  10.],\n",
       "       [ 10.,  10.],\n",
       "       [ 10.,  10.],\n",
       "       [ 10.,  10.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the variable `c` only refers to a view of the original array `myData`. Therefore, anything we do to `myData` will affect `c`, since `c` is only a reference to the original array. \n",
    "\n",
    "In contrast, when we created `b`, we explicitly requested the data from `myData` to be copied to a new array. Anything we subsequently do to `myData` will not affect the array `b`. Be sure to make copies of arrays when you need to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other methods\n",
    "**np.loadtxt** is not the only way of loading data. In fact, for large datasets, it is often very slow compared to other methods. I won't go into full detail here but there are other methods you can use such as:\n",
    "\n",
    "### `csv.reader`\n",
    "Python has a native csv (comma separated variable) file reader. Note that the CSV file doesn not have to actually be \"comma separated\" as you can specify what the delimter is. We can use it on our original (space separated) data file for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.2,   0.6,   0.6, ...,   0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ],\n",
       "       ..., \n",
       "       [  0.1,   1.1,   1. , ...,  12.5,  12.5,   3.6],\n",
       "       [  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. , ...,   0. ,   0. ,   0. ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "data = []  # create an empty list (note: not a numpy array, yet!)\n",
    "\n",
    "with open(\"test_rainfile_hourly.txt\", 'rb') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=\" \")\n",
    "    for row in csvreader:\n",
    "        data.append(row)  \n",
    "        \n",
    "dataArray = np.array(data, dtype=float)  # convert the standard python list into a swish numpy array\n",
    "dataArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's an important detail in the last couple of lines above. We specified a `dtype` - the type of data that the textfile contains. In our case, the data type is floating point numbers (`float`) - by default the csv reader will  generate strings, which is probably not what you want in scientific data processsing. We don't normally specify data types explicity in Python, but here's an example of when it is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `np.genfromtxt`\n",
    "This method is similar to `np.loadtxt` but offers a few more options, such as how to deal with missing values etc. For example if our data file contain NaNs, and we wanted to replace them with numbers, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataArray2 = np.genfromtxt(\"test_rainfile_hourly.txt\", missing_values=\"NaN\", filling_values=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some other options for `np.loadtxt` and `np.genfromtxt`\n",
    "There are some other nifty options for `loadtxt` and `genfromtxt` that you can use to easily pick out specific columns from a textfile, or skip header rows for example.\n",
    "\n",
    "#### usecols\n",
    "Pick out specific columns (do not have to be next to each other). Note that the 'first' column is column 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.2,   0.6,   0.6],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  1.5,   0.4,   0.4],\n",
       "       [ 15.8,  21.1,  21.1],\n",
       "       [  0. ,   1.7,   1.7],\n",
       "       [  0.3,   1.1,   1.1],\n",
       "       [  1. ,   1. ,   1. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0.1,   1. ,   1. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataArray3 = np.loadtxt(\"test_rainfile_hourly.txt\", usecols=(0,4,5))\n",
    "dataArray3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### skiprows\n",
    "Useful if you have header information in the text file. Or you just want to ignore given number of rows from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  1.5,   0.4,   0.4],\n",
       "       [ 15.8,  21.1,  21.1],\n",
       "       [  0. ,   1.7,   1.7],\n",
       "       [  0.3,   1.1,   1.1],\n",
       "       [  1. ,   1. ,   1. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0.1,   1. ,   1. ],\n",
       "       [  0. ,   0. ,   0. ],\n",
       "       [  0. ,   0. ,   0. ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataArray4 = np.loadtxt(\"test_rainfile_hourly.txt\", usecols=(0,4,5), skiprows=5)\n",
    "dataArray4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Unpacking' columns into separate variables\n",
    "This is a handy method for extracting colums into separate arrays. Insteading of getting one massive array for the whole dataset, we can get back back individual arrays for each one, by specifiying **unpack=True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.2   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    1.5  15.8   0.    0.3   1.    0.    0.    0.    0.1   0.    0. ]\n",
      "[  0.6   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.4  21.1   1.7   1.1   1.    0.    0.    0.    1.    0.    0. ]\n",
      "[  0.6   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.4  21.1   1.7   1.1   1.    0.    0.    0.    1.    0.    0. ]\n"
     ]
    }
   ],
   "source": [
    "x, y, z = np.loadtxt(\"test_rainfile_hourly.txt\", usecols=(0,4,5), unpack=True)\n",
    "\n",
    "print x\n",
    "print y\n",
    "print z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas.read_csv\n",
    "Pandas is a powerful Python module specifically aimed at data processing. It is separate from numpy, and probably best suited to situations when you want to do lots of loading and modifying of data tables. It has a level of functionality approaching database software. I won't go into it here but if you are interested in using it, there is a function called **read_csv** which has many, many options for reading text files into pandas data frames. Pandas dataframes can be easily converted into standard numpy arrays.\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/io.html#io-read-csv-table\n",
    "\n",
    "### Doing it the hard way...\n",
    "\n",
    "This is how I used to do it before I realised numpy had a `loadtxt` function (\\*facepalm\\*). This method could come in handy if you really need some fine-grained control over how the file was processed, or you have irregularly shaped data. For example, rows/columns of varying lengths. Here it is for completeness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"test_rainfile_hourly.txt\",'r')  # open file\n",
    "lines = f.readlines()[4:]   # read in the data using the readlines function (the last part skips 4 header lines)\n",
    "no_lines = len(lines)   # get the number of lines (=number of data)\n",
    "\n",
    "# data variables\n",
    "rainfall_zone1 = np.zeros(no_lines, dtype=np.float)\n",
    "rainfall_zone2 = np.zeros(no_lines, dtype=np.float)          \n",
    "rainfall_zone3 = np.zeros(no_lines, dtype=np.float)         \n",
    "rainfall_zone4 = np.zeros(no_lines, dtype=np.float) \n",
    "\n",
    "for i in range (0,no_lines):\n",
    "    line = lines[i].strip().split(\" \")\n",
    "    #print line\n",
    "    rainfall_zone1[i] = float(line[0])\n",
    "    rainfall_zone2[i] = float(line[1])\n",
    "    rainfall_zone3[i] = float(line[2])\n",
    "    rainfall_zone4[i] = float(line[3])\n",
    "\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it's clunky, but as you can see, the columns may be of different lengths and you will get the correctly sized arrays for each column. Of course, I could just have done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zone1, zone2, zone3, zone4 = np.loadtxt(\"test_rainfile_hourly.txt\", usecols=(0,1,2,3), unpack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **one line**. But you live and learn. (This is the result of coming to Python after learning C++, which probably would require twice as many lines of code, and then you'd get a memory leak etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "The np.loadtxt manual is here:\n",
    "http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.loadtxt.html\n",
    "\n",
    "A nice np.genfromtxt tutorial is here:\n",
    "http://students.mimuw.edu.pl/~pbechler/numpy_doc/user/basics.io.genfromtxt.html\n",
    "and the manual is here:\n",
    "http://docs.scipy.org/doc/numpy-1.10.1/user/basics.io.genfromtxt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Work with your own data. Try loading in a textfile that contains data you use, with an appropriate method from the ones discussed above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
